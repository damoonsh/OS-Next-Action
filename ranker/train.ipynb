{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6345abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./cleaned.csv')\n",
    "\n",
    "df.loc[df.prev_action_1.isna(), 'prev_action_1'] = 'FirstAction'\n",
    "df.loc[df.prev_action_2.isna(), 'prev_action_2'] = '2ndAction'\n",
    "df.loc[df.prev_action_3.isna(), 'prev_action_3'] = '3rdAction'\n",
    "\n",
    "df['parameters'] = df['parameters'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "df['para1'] = df['parameters'].apply(lambda x: x[0] if len(x) > 0 else 'NULL')\n",
    "df['para2'] = df['parameters'].apply(lambda x: x[1] if len(x) > 1 else 'NULL')\n",
    "df['para3'] = df['parameters'].apply(lambda x: x[2] if len(x) > 2 else 'NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e7d3d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRanker\n",
    "\n",
    "def create_ranking_dataset(df):\n",
    "    \"\"\"\n",
    "    Transform sequential data into ranking format for XGBRanker\n",
    "    Each context gets multiple candidate actions to rank\n",
    "    \"\"\"\n",
    "    ranking_data = []\n",
    "    group_sizes = []\n",
    "    \n",
    "    # Cast action and categorical columns as categorical\n",
    "    df['action'] = df['action'].astype('category')\n",
    "    cat_cols = ['prev_action_1', 'prev_action_2', 'prev_action_3', 'para1', 'para2', 'para3']\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    # Define context columns (features that define a unique context)\n",
    "    context_cols = ['prev_action_1', 'prev_action_2', 'prev_action_3', 'para1', 'para2', 'para3']\n",
    "    \n",
    "    # Group by context to create ranking groups\n",
    "    for context_id, group in df.groupby(context_cols, observed=False):\n",
    "        # Get all possible actions in the dataset\n",
    "        all_actions = df['action'].cat.categories.tolist()\n",
    "        \n",
    "        # Extract context features from the first row in this group\n",
    "        context_row = group[['seconds_passed', 'pa1_ss', 'pa2_ss', 'pa3_ss', \n",
    "                           'day', 'month', 'week', 'year'] + context_cols].iloc[0]\n",
    "        context_features = context_row.to_dict()\n",
    "        \n",
    "        # Create candidate-context pairs for each possible action\n",
    "        group_size = 0\n",
    "        for action in all_actions:\n",
    "            # Create features for this context-action pair\n",
    "            candidate_features = context_features.copy()\n",
    "            candidate_features['candidate_action'] = action\n",
    "            \n",
    "            # Label: 1 if this action was actually taken in this context, 0 otherwise\n",
    "            label = 1 if action in group['action'].values else 0\n",
    "            candidate_features['label'] = label\n",
    "            \n",
    "            ranking_data.append(candidate_features)\n",
    "            group_size += 1\n",
    "        \n",
    "        group_sizes.append(group_size)\n",
    "    \n",
    "    return pd.DataFrame(ranking_data), group_sizes\n",
    "\n",
    "def prepare_features(ranking_df):\n",
    "    \"\"\"\n",
    "    Prepare features for training\n",
    "    \"\"\"\n",
    "    # Cast candidate_action as categorical\n",
    "    ranking_df['candidate_action'] = ranking_df['candidate_action'].astype('category')\n",
    "    \n",
    "    # Define all feature columns\n",
    "    features = [\n",
    "        'seconds_passed', 'pa1_ss', 'pa2_ss', 'pa3_ss',\n",
    "        'day', 'month', 'week', 'year',\n",
    "        'prev_action_1', 'prev_action_2', 'prev_action_3',\n",
    "        'para1', 'para2', 'para3', 'candidate_action'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all categorical features are properly encoded\n",
    "    cat_cols = ['prev_action_1', 'prev_action_2', 'prev_action_3', \n",
    "                'para1', 'para2', 'para3', 'candidate_action']\n",
    "    for col in cat_cols:\n",
    "        if col in ranking_df.columns:\n",
    "            ranking_df[col] = ranking_df[col].astype('category')\n",
    "    \n",
    "    return features, cat_cols\n",
    "\n",
    "def train_xgb_ranker(X, y, group_sizes):\n",
    "    \"\"\"\n",
    "    Train XGBRanker model\n",
    "    \"\"\"\n",
    "    model = XGBRanker(\n",
    "        objective='rank:ndcg',\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        n_estimators=100,\n",
    "        enable_categorical=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X, y, group=group_sizes)\n",
    "    return model\n",
    "\n",
    "def predict_top_k_actions(model, context_features, all_actions, features_list, cat_cols, k=5):\n",
    "    \"\"\"\n",
    "    Predict top-k ranked actions for a given context\n",
    "    \n",
    "    Args:\n",
    "        model: Trained XGBRanker\n",
    "        context_features: Dictionary with context information\n",
    "        all_actions: List of all possible actions\n",
    "        features_list: List of feature names used in training\n",
    "        cat_cols: List of categorical column names\n",
    "        k: Number of top actions to return\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples (action, score) sorted by score descending\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    \n",
    "    # Create candidate features for each possible action\n",
    "    for action in all_actions:\n",
    "        candidate = context_features.copy()\n",
    "        candidate['candidate_action'] = action\n",
    "        candidates.append(candidate)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    candidates_df = pd.DataFrame(candidates)\n",
    "    \n",
    "    # Ensure categorical columns match training data\n",
    "    for col in cat_cols:\n",
    "        if col in candidates_df.columns:\n",
    "            candidates_df[col] = candidates_df[col].astype('category')\n",
    "    \n",
    "    # Predict scores\n",
    "    X_test = candidates_df[features_list]\n",
    "    scores = model.predict(X_test)\n",
    "    \n",
    "    # Rank actions by score\n",
    "    action_scores = list(zip(all_actions, scores))\n",
    "    ranked_actions = sorted(action_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return ranked_actions[:k]\n",
    "\n",
    "# Main execution pipeline\n",
    "def main():\n",
    "    # Assuming your DataFrame 'df' is already loaded with the required columns:\n",
    "    # ['action', 'seconds_passed', 'pa1_ss', 'pa2_ss', 'pa3_ss', \n",
    "    #  'day', 'month', 'week', 'year', 'prev_action_1', 'prev_action_2', \n",
    "    #  'prev_action_3', 'para1', 'para2', 'para3']\n",
    "    \n",
    "    print(\"Step 1: Creating ranking dataset...\")\n",
    "    ranking_df, group_sizes = create_ranking_dataset(df)\n",
    "    print(f\"Ranking dataset shape: {ranking_df.shape}\")\n",
    "    print(f\"Number of ranking groups: {len(group_sizes)}\")\n",
    "    \n",
    "    print(\"\\nStep 2: Preparing features...\")\n",
    "    features, cat_cols = prepare_features(ranking_df)\n",
    "    \n",
    "    X = ranking_df[features]\n",
    "    y = ranking_df['label']\n",
    "    print(f\"Training data shape: X={X.shape}, y={y.shape}\")\n",
    "    print(f\"Label distribution: {y.value_counts().to_dict()}\")\n",
    "    \n",
    "    print(\"\\nStep 3: Training XGBRanker...\")\n",
    "    model = train_xgb_ranker(X, y, group_sizes)\n",
    "    print(\"Model training completed!\")\n",
    "    \n",
    "    print(\"\\nStep 4: Testing predictions...\")\n",
    "    # Example context for prediction\n",
    "    test_context = {\n",
    "        'seconds_passed': 120,\n",
    "        'pa1_ss': 0.5,\n",
    "        'pa2_ss': 0.3,\n",
    "        'pa3_ss': 0.2,\n",
    "        'day': 15,\n",
    "        'month': 9,\n",
    "        'week': 37,\n",
    "        'year': 2025,\n",
    "        'prev_action_1': 'login',\n",
    "        'prev_action_2': 'browse',\n",
    "        'prev_action_3': 'search',\n",
    "        'para1': 'electronics',\n",
    "        'para2': 'mobile',\n",
    "        'para3': 'apple'\n",
    "    }\n",
    "    \n",
    "    all_actions = df['action'].cat.categories.tolist()\n",
    "    top_actions = predict_top_k_actions(model, test_context, all_actions, features, cat_cols, k=5)\n",
    "    \n",
    "    print(\"\\nTop 5 predicted actions:\")\n",
    "    for i, (action, score) in enumerate(top_actions, 1):\n",
    "        print(f\"{i}. {action}: {score:.4f}\")\n",
    "    \n",
    "    return model, features, cat_cols, all_actions\n",
    "\n",
    "# Alternative: Using native XGBoost with DMatrix (if you prefer the original approach)\n",
    "def train_with_dmatrix(ranking_df, group_sizes, features):\n",
    "    \"\"\"\n",
    "    Alternative training method using XGBoost DMatrix\n",
    "    \"\"\"\n",
    "    X = ranking_df[features]\n",
    "    y = ranking_df['label']\n",
    "    \n",
    "    # Create DMatrix\n",
    "    train_dmatrix = xgb.DMatrix(X, label=y, enable_categorical=True)\n",
    "    train_dmatrix.set_group(group_sizes)\n",
    "    \n",
    "    # Training parameters\n",
    "    params = {\n",
    "        'objective': 'rank:ndcg',\n",
    "        'eval_metric': 'ndcg@5',\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 6,\n",
    "        'lambdarank_pair_method': 'topk',\n",
    "        'lambdarank_num_pair_per_sample': 5,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = xgb.train(params, train_dmatrix, num_boost_round=100)\n",
    "    return model\n",
    "\n",
    "def predict_with_dmatrix(model, context_features, all_actions, features_list, cat_cols, k=5):\n",
    "    \"\"\"\n",
    "    Prediction function for DMatrix-trained model\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    for action in all_actions:\n",
    "        candidate = context_features.copy()\n",
    "        candidate['candidate_action'] = action\n",
    "        candidates.append(candidate)\n",
    "    \n",
    "    candidates_df = pd.DataFrame(candidates)\n",
    "    for col in cat_cols:\n",
    "        if col in candidates_df.columns:\n",
    "            candidates_df[col] = candidates_df[col].astype('category')\n",
    "    \n",
    "    X_test = xgb.DMatrix(candidates_df[features_list], enable_categorical=True)\n",
    "    scores = model.predict(X_test)\n",
    "    \n",
    "    action_scores = list(zip(all_actions, scores))\n",
    "    ranked_actions = sorted(action_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return ranked_actions[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0361ad1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Creating ranking dataset...\n",
      "Ranking dataset shape: (91392, 16)\n",
      "Number of ranking groups: 3264\n",
      "\n",
      "Step 2: Preparing features...\n",
      "Training data shape: X=(91392, 15), y=(91392,)\n",
      "Label distribution: {0: 88089, 1: 3303}\n",
      "\n",
      "Step 3: Training XGBRanker...\n",
      "Model training completed!\n",
      "\n",
      "Step 4: Testing predictions...\n",
      "\n",
      "Top 5 predicted actions:\n",
      "1. POST /sprints/{sprintId}/tickets: 0.4466\n",
      "2. PUT /budgets/{budget_id}: 0.1282\n",
      "3. PUT /costs/{service_id}/{cost_id}: 0.0901\n",
      "4. DELETE /tickets/{ticketId}: 0.0645\n",
      "5. PUT /invoices/{invoice_id}: 0.0585\n",
      "\n",
      "New prediction example:\n",
      "1. POST /sprints/{sprintId}/tickets: 0.4466\n",
      "2. PUT /budgets/{budget_id}: 0.1282\n",
      "3. PUT /costs/{service_id}/{cost_id}: 0.0901\n"
     ]
    }
   ],
   "source": [
    "model, features, cat_cols, all_actions = main()\n",
    "    \n",
    "# For new predictions:\n",
    "new_context = {\n",
    "        'seconds_passed': 90,\n",
    "        'pa1_ss': 0.7,\n",
    "        'pa2_ss': 0.4,\n",
    "        'pa3_ss': 0.1,\n",
    "        'day': 20,\n",
    "        'month': 10,\n",
    "        'week': 42,\n",
    "        'year': 2025,\n",
    "        'prev_action_1': 'browse',\n",
    "        'prev_action_2': 'search',\n",
    "        'prev_action_3': 'view',\n",
    "        'para1': 'books',\n",
    "        'para2': 'laptop',\n",
    "        'para3': 'samsung'\n",
    "    }\n",
    "    \n",
    "predictions = predict_top_k_actions(model, new_context, all_actions, features, cat_cols, k=3)\n",
    "print(\"\\nNew prediction example:\")\n",
    "for i, (action, score) in enumerate(predictions, 1):\n",
    "    print(f\"{i}. {action}: {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
